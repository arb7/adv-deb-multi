{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "from adversarial_debiasing_multi import AdversarialDebiasingMulti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "compas = pd.read_csv('data/compas.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ari/.virtualenvs/python3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "def prepare_meta_and_features(df, protected_attribute_name):\n",
    "    meta = df[[protected_attribute_name, 'label']]\n",
    "    features = df.drop(columns=[protected_attribute_name, 'label'])\n",
    "    \n",
    "    for col in features.columns:\n",
    "        data = features[col]\n",
    "        if pd.api.types.is_numeric_dtype(data):\n",
    "            data -= np.min(data,axis=0)\n",
    "            data /= (np.max(data,axis=0) - np.min(data,axis=0))\n",
    "            features[col] = data\n",
    "        else:\n",
    "            dummies = pd.get_dummies(data, prefix=col)\n",
    "            features[col] = dummies\n",
    "            \n",
    "    meta['label'] = meta.label.astype(int)\n",
    "    return meta, features\n",
    "\n",
    "meta, features = prepare_meta_and_features(compas, 'race')\n",
    "\n",
    "features_train, features_test, meta_train, meta_test = train_test_split(features, meta, test_size=0.2, random_state=42, stratify=meta.label)\n",
    "\n",
    "meta_train.reset_index(drop=True, inplace=True)\n",
    "meta_test.reset_index(drop=True, inplace=True)\n",
    "features_train.reset_index(drop=True, inplace=True)\n",
    "features_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(debias=True, fairness_def='parity', adv_loss_weight=2, prot_attr='race'):\n",
    "    sess = tf.compat.v1.Session()\n",
    "    model = AdversarialDebiasingMulti(\n",
    "        protected_attribute_name=prot_attr,\n",
    "        num_labels=len(meta_train.label.unique()),\n",
    "        scope_name='biased_classifier',\n",
    "        debias=debias,\n",
    "        adversary_loss_weight=adv_loss_weight,\n",
    "        fairness_def=fairness_def,\n",
    "        verbose=False,\n",
    "        num_epochs=64,\n",
    "        classifier_num_hidden_units_1=60,\n",
    "        classifier_num_hidden_units_2=20,\n",
    "        sess=sess\n",
    "    )\n",
    "    model.fit(features_train, meta_train)\n",
    "    predictions = model.predict(features_test, meta_test)\n",
    "    sess.close()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Binary Protected Attribute (Race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(df):\n",
    "    print('PERFORMANCE:\\n')\n",
    "    print(classification_report(df.label, df.pred_label))\n",
    "    print('\\nBIAS:')\n",
    "    rw = len(df.loc[(df.race==1) & (df.pred_label==1)]) / len(df.loc[df.race==1])\n",
    "    print('\\nproportion of White people predicted to reoffend: ' + str(rw))\n",
    "    rn = len(df.loc[(df.race==0) & (df.pred_label==1)]) / len(df.loc[df.race==0])\n",
    "    print('proportion of Nonwhite people predicted to reoffend: ' + str(rn))\n",
    "    print('\\tRATE GAP = ' + str(rw - rn))\n",
    "    tprw = len(df.loc[(df.race==1) & (df.pred_label==1) & (df.label==1)]) / len(df.loc[(df.race==1) & (df.label==1)])\n",
    "    print('\\nTPR for White people: ' + str(tprw))\n",
    "    tprn = len(df.loc[(df.race==0) & (df.pred_label==1) & (df.label==1)]) / len(df.loc[(df.race==0) & (df.label==1)])\n",
    "    print('TPR for Nonwhite people: ' + str(tprn))\n",
    "    print('\\tTPR GAP = ' + str(tprw - tprn))\n",
    "    fprw = len(df.loc[(df.race==1) & (df.pred_label==1) & (df.label==0)]) / len(df.loc[(df.race==1) & (df.label==0)])\n",
    "    print('\\nFPR for White people: ' + str(fprw))\n",
    "    fprn = len(df.loc[(df.race==0) & (df.pred_label==1) & (df.label==0)]) / len(df.loc[(df.race==0) & (df.label==0)])\n",
    "    print('FPR for Nonwhite people: ' + str(fprn))\n",
    "    print('\\tFPR GAP = ' + str(fprw - fprn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Ari/.virtualenvs/python3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "PERFORMANCE:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.70       672\n",
      "           1       0.64      0.60      0.62       562\n",
      "\n",
      "    accuracy                           0.66      1234\n",
      "   macro avg       0.66      0.66      0.66      1234\n",
      "weighted avg       0.66      0.66      0.66      1234\n",
      "\n",
      "\n",
      "BIAS:\n",
      "\n",
      "proportion of White people predicted to reoffend: 0.31386861313868614\n",
      "proportion of Nonwhite people predicted to reoffend: 0.4835965978128797\n",
      "\tRATE GAP = -0.1697279846741936\n",
      "\n",
      "TPR for White people: 0.4472049689440994\n",
      "TPR for Nonwhite people: 0.655860349127182\n",
      "\tTPR GAP = -0.20865538018308266\n",
      "\n",
      "FPR for White people: 0.228\n",
      "FPR for Nonwhite people: 0.31990521327014215\n",
      "\tFPR GAP = -0.09190521327014214\n"
     ]
    }
   ],
   "source": [
    "predictions = get_predictions(debias=False)\n",
    "print_stats(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parity Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.61      0.65       672\n",
      "           1       0.59      0.67      0.63       562\n",
      "\n",
      "    accuracy                           0.64      1234\n",
      "   macro avg       0.64      0.64      0.64      1234\n",
      "weighted avg       0.65      0.64      0.64      1234\n",
      "\n",
      "\n",
      "BIAS:\n",
      "\n",
      "proportion of White people predicted to reoffend: 0.44038929440389296\n",
      "proportion of Nonwhite people predicted to reoffend: 0.551640340218712\n",
      "\tRATE GAP = -0.11125104581481904\n",
      "\n",
      "TPR for White people: 0.5527950310559007\n",
      "TPR for Nonwhite people: 0.71571072319202\n",
      "\tTPR GAP = -0.16291569213611934\n",
      "\n",
      "FPR for White people: 0.368\n",
      "FPR for Nonwhite people: 0.3957345971563981\n",
      "\tFPR GAP = -0.02773459715639809\n"
     ]
    }
   ],
   "source": [
    "predictions = get_predictions(fairness_def='parity', adv_loss_weight=15)\n",
    "print_stats(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equal Odds Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.53      0.59       672\n",
      "           1       0.54      0.67      0.60       562\n",
      "\n",
      "    accuracy                           0.59      1234\n",
      "   macro avg       0.60      0.60      0.59      1234\n",
      "weighted avg       0.61      0.59      0.59      1234\n",
      "\n",
      "\n",
      "BIAS:\n",
      "\n",
      "proportion of White people predicted to reoffend: 0.48418491484184917\n",
      "proportion of Nonwhite people predicted to reoffend: 0.5990279465370595\n",
      "\tRATE GAP = -0.11484303169521032\n",
      "\n",
      "TPR for White people: 0.5900621118012422\n",
      "TPR for Nonwhite people: 0.7007481296758105\n",
      "\tTPR GAP = -0.11068601787456822\n",
      "\n",
      "FPR for White people: 0.416\n",
      "FPR for Nonwhite people: 0.5023696682464455\n",
      "\tFPR GAP = -0.08636966824644549\n"
     ]
    }
   ],
   "source": [
    "predictions = get_predictions(fairness_def='equal_odds', adv_loss_weight=50)\n",
    "print_stats(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Continuous Protected Attribute (Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ari/.virtualenvs/python3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "meta, features = prepare_meta_and_features(compas, 'age')\n",
    "\n",
    "features_train, features_test, meta_train, meta_test = train_test_split(features, meta, test_size=0.2, random_state=42, stratify=meta.label)\n",
    "\n",
    "meta_train.reset_index(drop=True, inplace=True)\n",
    "meta_test.reset_index(drop=True, inplace=True)\n",
    "features_train.reset_index(drop=True, inplace=True)\n",
    "features_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(df):\n",
    "    print('PERFORMANCE:\\n')\n",
    "    print(classification_report(df.label, df.pred_label))\n",
    "    print('\\nBIAS:')\n",
    "    corr = pearsonr(df.age, df.pred_label)[0]\n",
    "    corr_1 = pearsonr(df.loc[df.label==1].age, df.loc[df.label==1].pred_label)[0]\n",
    "    corr_0 = pearsonr(df.loc[df.label==0].age, df.loc[df.label==0].pred_label)[0]\n",
    "    print('\\nCorrelation between age and predicted label: ' + str(corr))\n",
    "    print('\\nCorrelation between age and predicted label, conditional on true label=1: ' + str(corr_1))\n",
    "    print('\\nCorrelation between age and predicted label, conditional on true label=0: ' + str(corr_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.70       672\n",
      "           1       0.64      0.61      0.62       562\n",
      "\n",
      "    accuracy                           0.67      1234\n",
      "   macro avg       0.66      0.66      0.66      1234\n",
      "weighted avg       0.66      0.67      0.66      1234\n",
      "\n",
      "\n",
      "BIAS:\n",
      "\n",
      "Correlation between age and predicted label: -0.2342970206582865\n",
      "\n",
      "Correlation between age and predicted label, conditional on true label=1: -0.12799579391774052\n",
      "\n",
      "Correlation between age and predicted label, conditional on true label=0: -0.23857925209720993\n"
     ]
    }
   ],
   "source": [
    "predictions = get_predictions(debias=False, prot_attr='age')\n",
    "print_stats(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parity Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.23      0.34       672\n",
      "           1       0.49      0.89      0.63       562\n",
      "\n",
      "    accuracy                           0.53      1234\n",
      "   macro avg       0.60      0.56      0.49      1234\n",
      "weighted avg       0.61      0.53      0.47      1234\n",
      "\n",
      "\n",
      "BIAS:\n",
      "\n",
      "Correlation between age and predicted label: 0.024079090559782818\n",
      "\n",
      "Correlation between age and predicted label, conditional on true label=1: 0.04695278610291956\n",
      "\n",
      "Correlation between age and predicted label, conditional on true label=0: 0.05651431668737571\n"
     ]
    }
   ],
   "source": [
    "predictions = get_predictions(prot_attr='age', fairness_def='parity', adv_loss_weight=0.00001)\n",
    "print_stats(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equal Odds Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.86      0.73       672\n",
      "           1       0.70      0.40      0.51       562\n",
      "\n",
      "    accuracy                           0.65      1234\n",
      "   macro avg       0.67      0.63      0.62      1234\n",
      "weighted avg       0.66      0.65      0.63      1234\n",
      "\n",
      "\n",
      "BIAS:\n",
      "\n",
      "Correlation between age and predicted label: -0.1621362925253865\n",
      "\n",
      "Correlation between age and predicted label, conditional on true label=1: -0.11367470319343426\n",
      "\n",
      "Correlation between age and predicted label, conditional on true label=0: -0.12385043989146062\n"
     ]
    }
   ],
   "source": [
    "predictions = get_predictions(prot_attr='age', fairness_def='equal_odds', adv_loss_weight=0.001)\n",
    "print_stats(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
